<!DOCTYPE html>
<html>
  <head>
    <title>OpenAI CLIP JavaScript - Text Demo - ONNX Web Runtime</title>
  </head>
  <body>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.9.0/dist/ort.js"></script>
    
    <div>
      input text <input id="textInputEl" value="hello world!">
      backend: <select id="backendSelectEl">
        <option>wasm</option>
        <option>webgl</option>
      </select>
      <button id="startBtn" onclick="main()">start</button>
    </div>
    <p><a href="https://github.com/josephrocca/openai-clip-js">github repo</a></p>
    
    <script>
      async function main() {
        startBtn.disabled = true;
        startBtn.innerHTML = "see console";
        
        console.log("Loading model... (see network tab for progress)");
        let modelPath = 'https://whitelist-cors-proxy-do-not-delete.glitch.me/api?url=https://huggingface.co/rocca/openai-clip-js/resolve/main/clip-text-vit-32-float32.onnx';
        const session = await ort.InferenceSession.create(modelPath, { executionProviders: [backendSelectEl.value] });
        console.log("Model loaded.");
        
        let Tokenizer = (await import("https://deno.land/x/clip_bpe@v0.0.6/mod.js")).default;
        let t = new Tokenizer();
        let textTokens = t.encodeForCLIP(textInputEl.value);
        textTokens = Float32Array.from(textTokens);
        const feeds = {'input': new ort.Tensor('float32', textTokens, [1, 77])};

        console.log("Running inference...");
        const results = await session.run(feeds);
        console.log("Finished inference.");

        const data = results["output"].data;
        console.log(`data of result tensor 'output'`, data);
      }
    </script>
  </body>
</html>
